[Versioning]
version = 1.0.0

[DataProcessing]
raw_data_path = data_lake, datasets, raw_data, challenge_MLE.csv
cleaned_data_path = data_lake, datasets, cleaned_data, cleaned_data.csv
ml_data_path = data_lake, datasets, ml_data, ml_data.csv

target_column = target
datetime_columns = fecha_mesa_epoch, ass_created_at, ass_due_at, ass_unlock_at, ass_lock_at, s_submitted_at, s_graded_at, s_created_at

[Modeling]
model_attr_path = data_lake, models

algorithms = random_forest, lightgbm, xgboost
eval_metric = f1_score
val_splits = 3
train_test_ratio = 0.2
n_candidates = 10
max_evals = 30
timeout_mins = 60
loss_threshold = -0.997
min_performance = 0.9

[Mlflow]
# 200.105.62.84
tracking_url = http://localhost:5050
local_registry = False
local_registry_path = data_lake, model_registry, model_registry.json
artifacts_path = data_lake, artifacts
experiment_name = dev_experiment

[Inference]
request_url = http://127.0.0.1:5001/predict
# request_url = http://model_serving_container_v.1.0.0:5000/predict
inference_path = data_lake, inferences
course_name = None
user_uuids = None
course_uuids = None
particion = None
pick_random = False

[Default]
raw_df = None
save = True
