[Versioning]
version = 1.0.0

[DataProcessing]
raw_data_path = data_lake, datasets, raw_data, challenge_MLE.csv
cleaned_data_path = data_lake, datasets, cleaned_data, cleaned_data.csv
ml_data_path = data_lake, datasets, ml_data, ml_data.csv

ignore_features = periodo, legajo
datetime_columns = fecha_mesa_epoch, ass_created_at, ass_due_at, ass_unlock_at, ass_lock_at, s_submitted_at, s_graded_at, s_created_at

[Modeling]
model_attr_path = data_lake, models

target_column = target
algorithms = random_forest, lightgbm, xgboost
eval_metric = f1_score
val_splits = 3
train_test_ratio = 0.2
n_candidates = 15
max_evals = 100
timeout_mins = 60
loss_threshold = -0.98
min_performance = 0.9

[Mlflow]
# 200.105.62.84
tracking_url = http://localhost:5050
local_registry = True
local_registry_path = data_lake, model_registry, model_registry.json
artifacts_path = data_lake, artifacts
experiment_name = dev_experiment

[Inference]
# request_url = http://127.0.0.1:5000/predict
request_url = http://model_serving_container_v.1.0.0:5000/predict
inference_path = data_lake, inferences

[Default]
raw_df = None
save = True
